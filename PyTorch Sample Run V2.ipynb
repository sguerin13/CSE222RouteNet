{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from model import RouteNet\n",
    "from CustomLoss import CustomLoss\n",
    "from SimpleNetworkDataset import NetworkDataset,get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"/home/steve/Documents/GitHub/CSE222a/CSE222RouteNet/data/pt_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_set = NetworkDataset(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = get_dataloader(data_set,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,x,label,n_packets):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), .001) # optimizer method for gradient descent\n",
    "#     criterion = torch.nn.MSELoss() \n",
    "    criterion = CustomLoss()\n",
    "    model.train() #put model in training mode\n",
    "    for epoch in range(100):\n",
    "        tr_loss = []\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(x)\n",
    "        #the input of the parameters should be re-defined here\n",
    "        loss = criterion(outputs, label,n_packets)\n",
    "        loss.backward()                        \n",
    "        optimizer.step()                  \n",
    "        tr_loss.append(loss.item())\n",
    "        print(tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _,batch in enumerate(dloader):\n",
    "    x,y = batch\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "'''using the implementation from RouteNet'''\n",
    "class RouteNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RouteNet,self).__init__()\n",
    "\n",
    "        ### Architecture ###\n",
    "        # for gru need to pay attention to if input is of size:\n",
    "        # (batch, seq_len, feature size) or seq_len, batch, feature size\n",
    "        # if sequence length is variable\n",
    "        # may need to pad the sequence\n",
    "        \n",
    "        self.link_state_dim = 32\n",
    "        self.path_state_dim = 32\n",
    "        self.readout_dim = 8\n",
    "        self.output_units = 2\n",
    "        self.T = 8\n",
    "\n",
    "        inSize = 10 # place holder\n",
    "        hSize  = 32\n",
    "        readSize = 10\n",
    "        nLayer = 1\n",
    "\n",
    "        self.l_U = nn.GRU(input_size = self.link_state_dim,\n",
    "                          hidden_size = hSize,\n",
    "                          num_layers = nLayer,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.p_U = nn.GRU(input_size = self.path_state_dim,\n",
    "                          hidden_size = hSize,\n",
    "                          num_layers = nLayer,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.readOut = nn.ModuleDict({  'r1': nn.Linear(hSize,self.readout_dim),\n",
    "                                        'r2': nn.Linear(self.readout_dim,self.readout_dim),\n",
    "                                        'r3': nn.Linear(self.readout_dim,self.output_units)\n",
    "                                        })\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        links = torch.unsqueeze(torch.tensor(x['links']),1)                         \n",
    "        paths = torch.unsqueeze(torch.tensor(x['paths']),1)                 \n",
    "        seqs = torch.unsqueeze(torch.tensor(x['sequences']),1)\n",
    "        link_cap = torch.unsqueeze(torch.tensor(x['link_capacity']).float(),axis=1)\n",
    "        link_cap = link_cap/torch.max(link_cap)\n",
    "        bandwidth = torch.unsqueeze(torch.tensor(x['bandwith']).float(), axis=1)\n",
    "        bandwidth = bandwidth/torch.max(bandwidth)\n",
    "\n",
    "        # state matrix shape for the link\n",
    "        link_h_state_shape = (x['n_links'][0], self.link_state_dim-1)\n",
    "\n",
    "        # create hidden state matrix shape for the path  \n",
    "        path_h_state_shape = (x['n_paths'],self.path_state_dim-1)\n",
    "        path_h_state = torch.cat((bandwidth,torch.zeros(path_h_state_shape)), axis=1)\n",
    "        \n",
    "        # prepare input for path update RNN\n",
    "        max_seq_len = torch.max(seqs)\n",
    "        path_rnn_input_shape = (x['n_paths'],max_seq_len+1,self.link_state_dim)\n",
    "        \n",
    "        #stack the paths and sequences\n",
    "        ids = torch.stack((paths,seqs),axis=1)\n",
    "        ids = torch.squeeze(ids,2)           \n",
    "        p_ind = ids[:,0]\n",
    "        s_ind = ids[:,1]\n",
    "\n",
    "        # flatten the double loop into a bulk matrix using the gather functionality\n",
    "        # this is an aggregation of the state vector of each link on each path flattened into a (sum_paths(sum_links_on_paths) x h_state) size matrix \n",
    "        # using torch.gather\n",
    "        indices = torch.zeros(len(links),32)\n",
    "        for i in range(len(links)):\n",
    "            link_id = links[i]\n",
    "            indices[i,:] = link_id\n",
    "            \n",
    "        # variable dictionary for forward pass\n",
    "        vd = {}\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            \n",
    "            \n",
    "            ############# set up the matrices and variables for each pass through #################\n",
    "            \n",
    "            ########## PATH VARIABLES ###########\n",
    "            \n",
    "            # input to the path rnn layer P_u\n",
    "            path_rnn_input_key = 'path_rnn_input_' + str(t)\n",
    "            vd[path_rnn_input_key] = torch.zeros(path_rnn_input_shape)\n",
    "            \n",
    "            if (t > 0):  # for non leaf variables, we need to propagate the gradient back\n",
    "                vd[path_rnn_input_key].requires_grad = True\n",
    "            \n",
    "            \n",
    "            # path hidden state output from P_U, initialized with just bandwidth at T_0, else copy\n",
    "            path_h_state_key = 'path_h_state_' + str(t)\n",
    "            if (t==0):\n",
    "                vd[path_h_state_key] = torch.cat((bandwidth,torch.zeros(path_h_state_shape)), axis=1)\n",
    "            else:\n",
    "                path_h_state_key = 'path_h_state_' + str(t)\n",
    "                path_h_prev = 'path_h_state_' + str(t-1)\n",
    "                vd[path_h_state_key] = vd[path_h_prev]\n",
    "            \n",
    "            \n",
    "            # path_hidden state sequence from P_U, used to update links\n",
    "            path_h_state_seq_key = 'path_h_states_seq_' + str(t)\n",
    "            \n",
    "            \n",
    "            ########## LINK VARIABLES ###########\n",
    "            \n",
    "            # vector to store the link_hidden states\n",
    "            if (t == 0):\n",
    "                # create hidden state matrix for links and initialize with first column as link capacity\n",
    "                link_h_state_key = 'link_h_state_' + str(t)\n",
    "                vd[link_h_state_key] = torch.cat((link_cap,torch.zeros(link_h_state_shape)),1)\n",
    "            else:\n",
    "                # copy hidden state value for next pass through\n",
    "                link_h_state_key = 'link_h_state_' + str(t)\n",
    "                linK_h_prev = 'link_h_state_' + str(t-1)\n",
    "                vd[link_h_state_key] = vd[linK_h_prev]\n",
    "                \n",
    "                \n",
    "            # matrix storing the hidden states of links on paths\n",
    "            # i.e. the hidden state of all links in the x['links'] list\n",
    "            h_link_path_key = 'h_links_on_paths_' + str(t)\n",
    "            vd[h_link_path_key] = torch.gather(vd[link_h_state_key],0,indices.long())\n",
    "            \n",
    "            #link messages extracted from the path hidden state sequence output from P_U\n",
    "            link_message_key = 'link_messages_' + str(t)\n",
    "\n",
    "            \n",
    "             # container for the link messages that are extracted from path rnn hidden states\n",
    "            agg_link_message_key = 'aggregated_link_message_' + str(t)\n",
    "            vd[agg_link_message_key] = torch.zeros((x['n_links'],self.link_state_dim),requires_grad=True)\n",
    "            \n",
    "            ########################################################################################\n",
    "            \n",
    "            \n",
    "            ################################## DO THE MESSAGE PASSING ##############################\n",
    "            \n",
    "            # prepare input for path RNN\n",
    "            vd[path_rnn_input_key] = vd[path_rnn_input_key].index_put(indices = [p_ind,s_ind],\n",
    "                                                                      values = vd[h_link_path_key])\n",
    "            # pass through the path RNN\n",
    "            vd[path_h_state_seq_key], vd[path_h_state_key] = self.p_U(vd[path_rnn_input_key],\n",
    "                                                                      torch.unsqueeze(vd[path_h_state_key],\n",
    "                                                                      0))\n",
    "            # reformat\n",
    "            vd[path_h_state_key] = vd[path_h_state_key].squeeze(0)\n",
    "            \n",
    "            # extract link messages from the path RNN sequence output\n",
    "            # equivalent to tf.gather_nd\n",
    "            vd[link_message_key] = vd[path_h_state_seq_key][p_ind,s_ind,:]\n",
    "           \n",
    "            # aggregate the link messages\n",
    "            vd[agg_link_message_key] = vd[agg_link_message_key].index_put([links.squeeze(1)],\n",
    "                                                                           vd[link_message_key],\n",
    "                                                                           accumulate=True)\n",
    "            # update the state of the links by passing through link \n",
    "            _, vd[link_h_state_key] = self.l_U(torch.unsqueeze(vd[agg_link_message_key],1),\n",
    "                                               torch.unsqueeze(vd[link_h_state_key].squeeze(0),0))\n",
    "            # reformat\n",
    "            vd[link_h_state_key] = vd[link_h_state_key].squeeze(0)\n",
    "            \n",
    "            ##########################################################################################\n",
    "\n",
    "        # readout from the paths\n",
    "        y = self.readout(vd[path_h_state_key])\n",
    "        return y\n",
    "\n",
    "\n",
    "    def readout(self,path_state):\n",
    "        x = F.relu(self.readOut['r1'](path_state))\n",
    "        x = F.relu(self.readOut['r2'](x))\n",
    "        x = self.readOut['r3'](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RouteNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.940240287543118]\n",
      "[10.864437724147267]\n",
      "[10.393563873358204]\n",
      "[9.686747783363767]\n",
      "[8.70490858703519]\n",
      "[8.040384995506853]\n",
      "[7.4026818804736925]\n",
      "[6.799327639681752]\n",
      "[6.232082177121792]\n",
      "[5.719573609463538]\n",
      "[5.27473293334764]\n",
      "[4.902551195836412]\n",
      "[4.555319747538169]\n",
      "[4.253224082751974]\n",
      "[3.9972590206604033]\n",
      "[3.7555454340576038]\n",
      "[3.5240834901789313]\n",
      "[3.302503538977329]\n",
      "[3.092297977460238]\n",
      "[2.8942203016111656]\n",
      "[2.7141375909380367]\n",
      "[2.551136908399257]\n",
      "[2.4003331377364465]\n",
      "[2.2617579222544006]\n",
      "[2.1339041467453423]\n",
      "[2.0139331985443216]\n",
      "[1.9010923814462812]\n",
      "[1.7947756233239576]\n",
      "[1.6946331114502715]\n",
      "[1.600378221317224]\n",
      "[1.511728041504864]\n",
      "[1.4291904480500075]\n",
      "[1.3518959030301283]\n",
      "[1.2793083700509928]\n",
      "[1.2111210934913699]\n",
      "[1.148032716753248]\n",
      "[1.0891574885704052]\n",
      "[1.0338307865024126]\n",
      "[0.9818163471028265]\n",
      "[0.932897848509977]\n",
      "[0.8868770322836436]\n",
      "[0.8435712782832505]\n",
      "[0.802811444334732]\n",
      "[0.7644404774014717]\n",
      "[0.7283117321064227]\n",
      "[0.6942878855341322]\n",
      "[0.6622405945750403]\n",
      "[0.632049392691]\n",
      "[0.6036006677053264]\n",
      "[0.5767879905710097]\n",
      "[0.5515115321343724]\n",
      "[0.5276769624735843]\n",
      "[0.5051959252664325]\n",
      "[0.48398542412237794]\n",
      "[0.46396716679417827]\n",
      "[0.4450676895394891]\n",
      "[0.4272176728598563]\n",
      "[0.41035231890315854]\n",
      "[0.3944100187651797]\n",
      "[0.3793331847647912]\n",
      "[0.36506768566764025]\n",
      "[0.3515626287232771]\n",
      "[0.33877026794019716]\n",
      "[0.32664585006333047]\n",
      "[0.3151475580400768]\n",
      "[0.3042362687354872]\n",
      "[0.293876027079132]\n",
      "[0.2840317118269272]\n",
      "[0.2746726037659161]\n",
      "[0.26576892759143056]\n",
      "[0.25729317742380636]\n",
      "[0.24921982484504046]\n",
      "[0.2415247924199098]\n",
      "[0.2341860992095427]\n",
      "[0.2271828718988736]\n",
      "[0.2204957828046425]\n",
      "[0.2141068365010698]\n",
      "[0.20799904146353243]\n",
      "[0.2021566418006556]\n",
      "[0.1965649055110212]\n",
      "[0.1912100634313937]\n",
      "[0.18607922366691068]\n",
      "[0.18116022602413673]\n",
      "[0.17644177641796274]\n",
      "[0.1719132077545343]\n",
      "[0.16756461287547025]\n",
      "[0.16338664801965996]\n",
      "[0.15937047185657727]\n",
      "[0.15550783501625545]\n",
      "[0.15179105501476556]\n",
      "[0.14821282027363836]\n",
      "[0.1447663694810019]\n",
      "[0.14144510880934763]\n",
      "[0.1382430578347193]\n",
      "[0.13515448338712086]\n",
      "[0.13217403461112276]\n",
      "[0.12929652532463196]\n",
      "[0.12651727614614822]\n",
      "[0.123831757165131]\n",
      "[0.12123565437435616]\n"
     ]
    }
   ],
   "source": [
    "train(model,x,y,x['packets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
