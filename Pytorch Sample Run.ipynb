{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-072084f2191c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRouteNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mread_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/CSE222RouteNet/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from model import RouteNet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from read_dataset import generator\n",
    "import os\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "tr_path = r'/Users/yanchuanqi/Github/CSE222RouteNet/sample_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_dataset_tf import generator\n",
    "tr_path = r'/Users/yanchuanqi/Github/CSE222RouteNet/sample_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None 10000 None None None 25000 None None None None None None None None\n",
      "  None None None None None]\n",
      " [10000 None 10000 None 10000 40000 None None None None None None None\n",
      "  None None None None 10000 10000]\n",
      " [None 10000 None 25000 None None None None None None None None None None\n",
      "  None None None None None]\n",
      " [None None 25000 None None 40000 None None None None None None None None\n",
      "  None None None None None]\n",
      " [None 10000 None None None 25000 None None None None None None None None\n",
      "  None None None None None]\n",
      " [25000 40000 None 40000 25000 None 25000 25000 40000 None None 40000\n",
      "  None None 40000 40000 None 25000 None]\n",
      " [None None None None None 25000 None None None None None None None None\n",
      "  None None None None None]\n",
      " [None None None None None 25000 None None 10000 None None None None\n",
      "  10000 None None None None None]\n",
      " [None None None None None 40000 None 10000 None 25000 None 10000 None\n",
      "  None None None None None None]\n",
      " [None None None None None None None None 25000 None 10000 None None None\n",
      "  None None None None None]\n",
      " [None None None None None None None None None 10000 None 25000 None None\n",
      "  None None None None None]\n",
      " [None None None None None 40000 None None 10000 None 25000 None 10000\n",
      "  None None None None None None]\n",
      " [None None None None None None None None None None None 10000 None None\n",
      "  25000 None None None None]\n",
      " [None None None None None None None 10000 None None None None None None\n",
      "  25000 None None None None]\n",
      " [None None None None None 40000 None None None None None None 25000\n",
      "  25000 None 10000 None None None]\n",
      " [None None None None None 40000 None None None None None None None None\n",
      "  10000 None 10000 10000 None]\n",
      " [None None None None None None None None None None None None None None\n",
      "  None 10000 None 10000 None]\n",
      " [None 10000 None None None 25000 None None None None None None None None\n",
      "  None 10000 10000 None 10000]\n",
      " [None 10000 None None None None None None None None None None None None\n",
      "  None None None 10000 None]]\n",
      "(19, 19)\n"
     ]
    }
   ],
   "source": [
    "for batch, delay in generator(tr_path):\n",
    "    x = batch\n",
    "    y = delay\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "x['links'] = torch.unsqueeze(torch.tensor(x['links']),1)                         \n",
    "x['paths'] = torch.unsqueeze(torch.tensor(x['paths']),1)                 \n",
    "x['sequences'] = torch.unsqueeze(torch.tensor(x['sequences']),1)\n",
    "x['link_capacity'] = torch.unsqueeze(torch.tensor(x['link_capacity']).float(),axis=1)\n",
    "x['bandwith'] = torch.unsqueeze(torch.tensor(x['bandwith']).float(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RouteNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RouteNet,self).__init__()\n",
    "\n",
    "        ### Architecture ###\n",
    "        # for gru need to pay attention to if input is of size:\n",
    "        # (batch, seq_len, feature size) or seq_len, batch, feature size\n",
    "        # if sequence length is variable\n",
    "        # may need to pad the sequence\n",
    "        \n",
    "        self.link_state_dim = 32\n",
    "        self.path_state_dim = 32\n",
    "        self.readout_dim = 8\n",
    "        self.output_units = 1\n",
    "        self.T = 8\n",
    "\n",
    "        inSize = 10 # place holder\n",
    "        hSize  = 32\n",
    "        readSize = 10\n",
    "        nLayer = 1\n",
    "\n",
    "        self.l_U = nn.GRU(input_size = self.link_state_dim,\n",
    "                          hidden_size = hSize,\n",
    "                          num_layers = nLayer,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.p_U = nn.GRU(input_size = self.path_state_dim,\n",
    "                          hidden_size = hSize,\n",
    "                          num_layers = nLayer,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.readOut = nn.ModuleDict({  'r1': nn.Linear(hSize,self.readout_dim),\n",
    "                                        'r2': nn.Linear(self.readout_dim,self.readout_dim),\n",
    "                                        'r3': nn.Linear(self.readout_dim,self.output_units)\n",
    "                                        })\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        links = x['links']\n",
    "        paths = x['paths']\n",
    "        seqs  = x['sequences']\n",
    "        bandwidth = x['bandwith']\n",
    "        link_cap  = x['link_capacity']\n",
    "\n",
    "        # state matrix shape for the link\n",
    "        link_h_state_shape = (x['n_links'], self.link_state_dim-1)\n",
    "\n",
    "        # create hidden state matrix shape for the path  \n",
    "        path_h_state_shape = (x['n_paths'],self.path_state_dim-1)\n",
    "        path_h_state = torch.cat((bandwidth,torch.zeros(path_h_state_shape)), axis=1)\n",
    "        \n",
    "        # prepare input for path update RNN\n",
    "        max_seq_len = torch.max(seqs)\n",
    "        path_rnn_input_shape = (x['n_paths'],max_seq_len+1,self.link_state_dim)\n",
    "        \n",
    "        #stack the paths and sequences\n",
    "        ids = torch.stack((paths,seqs),axis=1)\n",
    "        ids = torch.squeeze(ids,2)           \n",
    "        p_ind = ids[:,0]\n",
    "        s_ind = ids[:,1]\n",
    "\n",
    "        # flatten the double loop into a bulk matrix using the gather functionality\n",
    "        # this is an aggregation of the state vector of each link on each path flattened into a (sum_paths(sum_links_on_paths) x h_state) size matrix \n",
    "        # using torch.gather\n",
    "        indices = torch.zeros(len(links),32)\n",
    "        for i in range(len(links)):\n",
    "            link_id = links[i]\n",
    "            indices[i,:] = link_id\n",
    "            \n",
    "        # variable dictionary for forward pass\n",
    "        vd = {}\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            \n",
    "            \n",
    "            ############# set up the matrices and variables for each pass through #################\n",
    "            \n",
    "            ########## PATH VARIABLES ###########\n",
    "            \n",
    "            # input to the path rnn layer P_u\n",
    "            path_rnn_input_key = 'path_rnn_input_' + str(t)\n",
    "            vd[path_rnn_input_key] = torch.zeros(path_rnn_input_shape)\n",
    "            \n",
    "            if (t > 0):  # for non leaf variables, we need to propagate the gradient back\n",
    "                vd[path_rnn_input_key].requires_grad = True\n",
    "            \n",
    "            \n",
    "            # path hidden state output from P_U, initialized with just bandwidth at T_0, else copy\n",
    "            path_h_state_key = 'path_h_state_' + str(t)\n",
    "            if (t==0):\n",
    "                vd[path_h_state_key] = torch.cat((bandwidth,torch.zeros(path_h_state_shape)), axis=1)\n",
    "            else:\n",
    "                path_h_state_key = 'path_h_state_' + str(t)\n",
    "                path_h_prev = 'path_h_state_' + str(t-1)\n",
    "                vd[path_h_state_key] = vd[path_h_prev]\n",
    "            \n",
    "            \n",
    "            # path_hidden state sequence from P_U, used to update links\n",
    "            path_h_state_seq_key = 'path_h_states_seq_' + str(t)\n",
    "            \n",
    "            \n",
    "            ########## LINK VARIABLES ###########\n",
    "            \n",
    "            # vector to store the link_hidden states\n",
    "            if (t == 0):\n",
    "                # create hidden state matrix for links and initialize with first column as link capacity\n",
    "                link_h_state_key = 'link_h_state_' + str(t)\n",
    "                vd[link_h_state_key] = torch.cat((link_cap,torch.zeros(link_h_state_shape)),1)\n",
    "            else:\n",
    "                # copy hidden state value for next pass through\n",
    "                link_h_state_key = 'link_h_state_' + str(t)\n",
    "                linK_h_prev = 'link_h_state_' + str(t-1)\n",
    "                vd[link_h_state_key] = vd[linK_h_prev]\n",
    "                \n",
    "                \n",
    "            # matrix storing the hidden states of links on paths\n",
    "            # i.e. the hidden state of all links in the x['links'] list\n",
    "            h_link_path_key = 'h_links_on_paths_' + str(t)\n",
    "            vd[h_link_path_key] = torch.gather(vd[link_h_state_key],0,indices.long())\n",
    "            \n",
    "            #link messages extracted from the path hidden state sequence output from P_U\n",
    "            link_message_key = 'link_messages_' + str(t)\n",
    "\n",
    "            \n",
    "             # container for the link messages that are extracted from path rnn hidden states\n",
    "            agg_link_message_key = 'aggregated_link_message_' + str(t)\n",
    "            vd[agg_link_message_key] = torch.zeros((x['n_links'],self.link_state_dim),requires_grad=True)\n",
    "            \n",
    "            ########################################################################################\n",
    "            \n",
    "            \n",
    "            ################################## DO THE MESSAGE PASSING ##############################\n",
    "            \n",
    "            # prepare input for path RNN\n",
    "            vd[path_rnn_input_key] = vd[path_rnn_input_key].index_put(indices = [p_ind,s_ind],\n",
    "                                                                      values = vd[h_link_path_key])\n",
    "            # pass through the path RNN\n",
    "            vd[path_h_state_seq_key], vd[path_h_state_key] = self.p_U(vd[path_rnn_input_key],\n",
    "                                                                      torch.unsqueeze(vd[path_h_state_key],\n",
    "                                                                      0))\n",
    "            # reformat\n",
    "            vd[path_h_state_key] = vd[path_h_state_key].squeeze(0)\n",
    "            \n",
    "            # extract link messages from the path RNN sequence output\n",
    "            # equivalent to tf.gather_nd\n",
    "            vd[link_message_key] = vd[path_h_state_seq_key][p_ind,s_ind,:]\n",
    "           \n",
    "            # aggregate the link messages\n",
    "            vd[agg_link_message_key] = vd[agg_link_message_key].index_put([links.squeeze(1)],\n",
    "                                                                           vd[link_message_key],\n",
    "                                                                           accumulate=True)\n",
    "            # update the state of the links by passing through link \n",
    "            _, vd[link_h_state_key] = self.l_U(torch.unsqueeze(vd[agg_link_message_key],1),\n",
    "                                               torch.unsqueeze(vd[link_h_state_key].squeeze(0),0))\n",
    "            # reformat\n",
    "            vd[link_h_state_key] = vd[link_h_state_key].squeeze(0)\n",
    "            \n",
    "            ##########################################################################################\n",
    "\n",
    "        # readout from the paths\n",
    "        y = self.readout(vd[path_h_state_key])\n",
    "        return y\n",
    "\n",
    "\n",
    "    def readout(self,path_state):\n",
    "        x = F.relu(self.readOut['r1'](path_state))\n",
    "        x = F.relu(self.readOut['r2'](x))\n",
    "        x = self.readOut['r3'](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code snippet from runner\n",
    "\n",
    "def train(model,label):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), .001) # optimizer method for gradient descent\n",
    "#     criterion = torch.nn.MSELoss() \n",
    "    criterion = CustomLoss(100)\n",
    "    model.train() #put model in training mode\n",
    "    for epoch in range(10):\n",
    "        tr_loss = []\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(x)\n",
    "        print(outputs[0].dtype,torch.tensor(label)[0].dtype)\n",
    "        #the input of the parameters should be re-defined here\n",
    "        loss = criterion(outputs, torch.unsqueeze(torch.tensor(label),1)) \n",
    "        loss.backward()                        \n",
    "        optimizer.step()                  \n",
    "        tr_loss.append(loss.item())\n",
    "        print(torch.mean(torch.tensor(tr_loss)))\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, num_packet, , , , ): \n",
    "        # maybe it's not a great idea to throw all the output into the init function\n",
    "        # it should be okay to put them as the input parameter of the forward method, but I haven't been able to test it\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.n = num_packet\n",
    "        self.d = \n",
    "        self.d_t = \n",
    "        self.j =\n",
    "        self.j_t =\n",
    "        \n",
    "    def forward(self):\n",
    "        # calculate the negative log-likelihood and return their average\n",
    "        nll = -self.n * ((self.j_t + (self.d_t - self.d)**2)/(2*self.j**2) + torch.log(self.j))\n",
    "        return torch.mean(nll)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RouteNet()\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_dot(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n",
      "tensor(-1.0167)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0205)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0279)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0353)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0440)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0510)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0578)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0649)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0723)\n",
      "torch.float32 torch.float32\n",
      "tensor(-1.0804)\n"
     ]
    }
   ],
   "source": [
    "train(model,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8323bb798931>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtr_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tr_loss' is not defined"
     ]
    }
   ],
   "source": [
    "tr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "a = torch.tensor([1.,2.,3.])\n",
    "b = torch.tensor([6.,5.,4.])\n",
    "c = torch.tensor([7.,8.,9.])\n",
    "d = torch.tensor([10.,11.,12.])\n",
    "e = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3031, -4.4714, -6.8324])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-e * (d/(2 * c**2) + (b-a)**2/(2 * c**2) + torch.log(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
